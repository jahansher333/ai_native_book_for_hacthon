# LiteLLM RAG Agent Test Report

**Test Date:** December 7, 2025, 7:10 PM PKT
**Backend URL:** https://web-production-d0418.up.railway.app/
**Agent Implementation:** `backend/src/ai_agents/litellm_converted/rag_agent.py`
**Model:** `groq/llama-3.3-70b-versatile`

---

## âœ… Deployment Status: SUCCESS

### Backend Deployment:
- **Status:** âœ… LIVE and responding
- **Platform:** Railway (Docker deployment)
- **Container:** Running successfully
- **API Documentation:** âœ… Available at `/docs`
- **Root Endpoint:** âœ… Responding

```json
{
  "message": "RAG Chatbot API",
  "version": "1.0.0",
  "status": "running"
}
```

---

## ğŸ” LiteLLM RAG Agent Architecture

### Agent Configuration (from rag_agent.py:89-118):

**Model:**
```python
groq_model = LitellmModel(
    model="groq/llama-3.3-70b-versatile",  # Groq LLM
    api_key=groq_api_key
)
```

**Agent:**
```python
rag_agent = Agent(
    name="TextbookAssistant",
    instructions="...",  # 200+ lines of detailed instructions
    tools=[search_textbook],  # RAG retrieval function
    model=groq_model
)
```

**RAG Tool (search_textbook):**
- **Purpose:** Semantic search of textbook content
- **Process:**
  1. Embeds query using Gemini API (embeddings only)
  2. Searches Qdrant vector database
  3. Returns top-k relevant chunks with citations
  4. Groq LLM generates answer using retrieved context

---

## ğŸ§ª Test Results

### Test 1: Health Check
**Endpoint:** `GET /api/health`
**Status:** âš ï¸ DEGRADED

**Response:**
```json
{
  "status": "degraded",
  "services": {
    "qdrant": "unhealthy",
    "neon": "unhealthy",
    "gemini": "unhealthy"
  }
}
```

**Analysis:**
- Backend is running but external services are not connected
- Missing API keys in Railway environment variables

---

### Test 2: Query Endpoint
**Endpoint:** `POST /api/query`
**Status:** âŒ FAILING

**Request:**
```json
{
  "question": "What is ROS2?",
  "mode": "general"
}
```

**Response:**
```json
{
  "detail": "Failed to process query: 'NoneType' object is not callable"
}
```

**Root Cause Analysis:**

#### Line-by-Line Failure Trace:

1. **rag_agent.py:36** - Groq API key loading:
   ```python
   groq_api_key = os.getenv("GROQ_API_KEY")
   ```
   - Returns `None` (not set in Railway)

2. **rag_agent.py:89-92** - Model initialization:
   ```python
   groq_model = LitellmModel(
       model="groq/llama-3.3-70b-versatile",
       api_key=groq_api_key  # groq_api_key is None
   )
   ```
   - Creates model with `api_key=None`

3. **Query Endpoint** - When user sends query:
   - Agent tries to call `groq_model()` for completion
   - LiteLLM client is `None` because no API key
   - Results in: `'NoneType' object is not callable`

---

### Test 3: API Documentation
**Endpoint:** `GET /docs`
**Status:** âœ… WORKING

**Response:**
```html
<title>RAG Chatbot API - Swagger UI</title>
```

- Swagger UI is accessible
- All endpoints documented
- Interactive API testing available

---

## ğŸ”‘ Missing Environment Variables

The LiteLLM RAG agent **CANNOT function** without these API keys:

### Critical (Must Set):

1. **GROQ_API_KEY** â† **PRIMARY BLOCKER**
   - **Used for:** LLM chat responses via `groq/llama-3.3-70b-versatile`
   - **Get from:** https://console.groq.com/keys
   - **Code:** `backend/src/ai_agents/litellm_converted/rag_agent.py:36`
   - **Impact:** Agent cannot generate responses

2. **GEMINI_API_KEY**
   - **Used for:** Text embeddings ONLY (not chat)
   - **Get from:** https://aistudio.google.com/apikey
   - **Code:** `backend/src/services/embeddings.py`
   - **Impact:** Cannot convert queries to vectors

3. **QDRANT_URL** + **QDRANT_API_KEY**
   - **Used for:** Vector search of textbook
   - **Get from:** https://cloud.qdrant.io/
   - **Code:** `backend/src/services/vector_store.py`
   - **Impact:** Cannot retrieve relevant textbook chunks

### Optional (Auth/Logging):

4. **NEON_DATABASE_URL**
   - **Used for:** User authentication and query logging
   - **Get from:** https://neon.tech/
   - **Impact:** Auth and history features disabled

5. **JWT_SECRET**
   - **Used for:** Secure authentication tokens
   - **Generate:** Random 32+ character string
   - **Impact:** Login/signup won't work

6. **CORS_ORIGINS**
   - **Used for:** Frontend access control
   - **Default:** `http://localhost:3000`
   - **Impact:** Frontend may be blocked

---

## ğŸ“Š LiteLLM RAG Agent Flow (When Working)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Question: "What is ROS2?"             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: search_textbook() Tool             â”‚
â”‚  rag_agent.py:40-85                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Embed Query (Gemini)              â”‚
â”‚  embeddings.py (GEMINI_API_KEY)             â”‚
â”‚  Output: 768-dim vector                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Vector Search (Qdrant)            â”‚
â”‚  vector_store.py (QDRANT_URL/KEY)           â”‚
â”‚  Output: Top-5 relevant chunks              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Format Context with Citations     â”‚
â”‚  rag_agent.py:67-82                         â”‚
â”‚  Output: "[Source 1]...[Source 2]..."      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Generate Answer (Groq LLM)        â”‚
â”‚  rag_agent.py:89-92 (GROQ_API_KEY)          â”‚
â”‚  Model: llama-3.3-70b-versatile             â”‚
â”‚  Output: AI answer + citations              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 6: Return Response                    â”‚
â”‚  {answer, citations, query_id, latency}     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Current Blocker:** Step 5 fails because `GROQ_API_KEY` is `None`

---

## ğŸ¯ Agent Instructions (from rag_agent.py:97-118)

The agent has **200+ lines of detailed instructions** including:

### Critical Rules:
1. **Book-Only Retrieval:** Answer ONLY from textbook
2. **Always Cite Sources:** Format: `[Source: Module - Section, Page X]`
3. **Must Use search_textbook:** NEVER answer without searching first
4. **Refuse Non-Textbook Questions:** Politely decline off-topic queries
5. **Prioritize Selected Text:** If user provides text, focus on that
6. **Be Concise:** 2-4 paragraphs maximum

### Textbook Modules:
- Module 1: ROS 2 Fundamentals
- Module 2: Gazebo Simulator
- Module 3: Unity for Robotics
- Module 4: Isaac Sim
- Module 5: Vision-Language-Action (VLA) Models
- Module 6: Hardware and GPU Requirements

---

## ğŸš€ Next Steps to Make Agent Functional

### Step 1: Set API Keys in Railway
1. Go to Railway Dashboard: https://railway.app/
2. Select your project
3. Click **Variables** tab
4. Add these variables:

```bash
GROQ_API_KEY=gsk_...              # Get from https://console.groq.com/keys
GEMINI_API_KEY=...                # Get from https://aistudio.google.com/apikey
QDRANT_URL=https://....qdrant.io  # Get from https://cloud.qdrant.io/
QDRANT_API_KEY=...
QDRANT_COLLECTION_NAME=book_vectors
NEON_DATABASE_URL=postgresql://...  # Get from https://neon.tech/
JWT_SECRET=<random-32-chars>
CORS_ORIGINS=http://localhost:3000,https://ai-native-books-pyhsical-ai-kcpd.vercel.app,https://web-production-d0418.up.railway.app
```

5. Click **Save**
6. Railway will automatically redeploy (~2-3 minutes)

---

### Step 2: Wait for Redeploy
Watch the **Deployments** tab in Railway Dashboard for:
- âœ… Build successful
- âœ… Deploy successful
- âœ… Service running

---

### Step 3: Verify Health
```bash
curl https://web-production-d0418.up.railway.app/api/health
```

**Expected (after API keys set):**
```json
{
  "status": "healthy",
  "services": {
    "qdrant": "healthy",
    "neon": "healthy",
    "gemini": "healthy"
  }
}
```

---

### Step 4: Test RAG Agent
```bash
curl -X POST https://web-production-d0418.up.railway.app/api/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is ROS2?",
    "mode": "general"
  }'
```

**Expected Response:**
```json
{
  "answer": "ROS 2 is the next generation of the Robot Operating System... [Source: ROS 2 - Introduction, Page 5]",
  "citations": [
    {
      "module": "ROS 2",
      "section": "Introduction",
      "page": 5,
      "relevance_score": 0.92
    }
  ],
  "query_id": "uuid...",
  "latency_ms": 2500,
  "timestamp": "2025-12-07T..."
}
```

---

## ğŸ“ Testing Checklist

### Deployment: âœ… COMPLETE
- [x] Backend deployed to Railway
- [x] Docker container running
- [x] Port configuration correct (using Railway's PORT variable)
- [x] API documentation accessible at `/docs`
- [x] Root endpoint responding
- [x] No crashes or container restarts

### Configuration: âŒ INCOMPLETE
- [ ] GROQ_API_KEY set in Railway
- [ ] GEMINI_API_KEY set in Railway
- [ ] QDRANT_URL and QDRANT_API_KEY set
- [ ] NEON_DATABASE_URL set
- [ ] JWT_SECRET set
- [ ] CORS_ORIGINS configured

### Testing: â³ PENDING API KEYS
- [ ] Health check shows "healthy"
- [ ] Query endpoint returns AI responses
- [ ] Citations included in responses
- [ ] Selected text mode works
- [ ] Session tracking works
- [ ] Rate limiting handled
- [ ] Error messages are clear
- [ ] Response times acceptable (<5s)

---

## ğŸ’¡ Testing Tools Available

### 1. Interactive Web UI:
Open `test-groq-agent.html` in browser for:
- Real-time health monitoring
- Example query buttons
- Response visualization with citations
- Latency tracking

### 2. Automated Shell Script:
Run `./test-api-keys.sh` for comprehensive tests:
- Health checks
- Query tests
- Error handling
- Performance benchmarks

### 3. cURL Commands:
See `TEST_GROQ_LITELLM.md` for:
- 8 test scenarios
- Expected responses
- Debugging tips

---

## ğŸ“ˆ Performance Expectations (Once Working)

### Latency Breakdown:
- **Embedding generation:** ~200-500ms (Gemini)
- **Vector search:** ~100-200ms (Qdrant)
- **LLM response:** ~1-3s (Groq)
- **Total latency:** ~2-4s

### Groq Model Benefits:
- **Model:** `llama-3.3-70b-versatile`
- **Speed:** Fast inference (optimized hardware)
- **Quality:** High-quality responses
- **Cost:** 90% cheaper than Gemini (as noted in code)
- **Rate Limits:** Free tier available

---

## ğŸ¯ Summary

### What's Working: âœ…
1. âœ… Backend deployed to Railway successfully
2. âœ… Docker container running without crashes
3. âœ… API endpoints registered and responding
4. âœ… Swagger documentation available
5. âœ… Error handling graceful (no crashes)
6. âœ… Frontend updated to use Railway URL
7. âœ… LiteLLM RAG agent code loaded

### What's Blocked: âŒ
1. âŒ Groq API key not set â†’ Cannot generate responses
2. âŒ Gemini API key not set â†’ Cannot create embeddings
3. âŒ Qdrant credentials not set â†’ Cannot search textbook
4. âŒ Query endpoint returns NoneType error

### Root Cause: ğŸ”‘
**Missing environment variables in Railway Dashboard**

### Solution: âš¡
**Set API keys in Railway â†’ Automatic redeploy â†’ Agent will work**

### ETA to Functional: â±ï¸
**~5 minutes** (3 min to add keys + 2 min redeploy)

---

## ğŸ”— Quick Links

- **Backend URL:** https://web-production-d0418.up.railway.app/
- **API Docs:** https://web-production-d0418.up.railway.app/docs
- **Groq Console:** https://console.groq.com/keys
- **Gemini API:** https://aistudio.google.com/apikey
- **Qdrant Cloud:** https://cloud.qdrant.io/
- **Neon Database:** https://neon.tech/
- **Railway Dashboard:** https://railway.app/

---

**Test Status:** âš ï¸ Deployment successful, but agent cannot function without API keys.
**Next Action:** Set environment variables in Railway to enable LiteLLM RAG agent functionality.
