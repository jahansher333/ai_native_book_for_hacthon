# Feature Specification: 8 Ultimate Reusable Claude Code Subagents

**Feature ID**: 003-claude-code-subagents
**Feature Branch**: `003-claude-code-subagents`
**Created**: 2025-12-06
**Status**: Draft
**Priority**: P1 (High - 50+ Bonus Points)
**Dependencies**: None (foundational infrastructure)

---

## Executive Summary

This specification defines **8 specialized Claude Code subagents** that serve as reusable, intelligent assistants for authoring the Physical AI & Humanoid Robotics textbook. Each subagent has a distinct role, expertise domain, and system prompt (500+ words) that ensures consistency, accuracy, and adherence to the project constitution.

**Key Value Proposition**:
- ✅ **Consistent Quality**: Every chapter follows constitution principles automatically
- ✅ **Domain Expertise**: Each agent is a specialist (content, research, proofreading, etc.)
- ✅ **Traceability**: All generated content is tagged with agent name and timestamp
- ✅ **Reusability**: Agents work across all 4 modules without modification
- ✅ **50+ Bonus Points**: Demonstrates advanced multi-agent orchestration

---

## User Stories & Testing *(mandatory)*

### User Story 1 - Content Generation with @content-generator (Priority: P1)

**As a** course author,
**I want to** invoke `@content-generator` to create a full chapter (e.g., "ROS 2 Pub/Sub") with code examples, diagrams, and MDX components,
**So that** I get publication-ready content that follows constitution principles without manual formatting.

**Why this priority**: Content generation is the primary workflow—this agent must work flawlessly before others.

**Independent Test**:
- Run: `@content-generator "Write Module 1 Chapter 3: ROS 2 Pub/Sub with Python talker/listener example"`
- Verify: Output is valid MDX with code blocks, follows constitution, ends with `<!-- Generated by @content-generator on 2025-12-06 -->`

**Acceptance Scenarios**:

1. **Given** a chapter outline, **When** @content-generator is invoked, **Then** it produces 1500-2500 word MDX with:
   - Clear headings hierarchy (H2, H3)
   - At least 1 Python/C++ code example
   - At least 1 diagram (Mermaid or SVG)
   - Beginner-friendly explanations
   - Constitution compliance (no cloud-robot control, accurate pricing)
   - Footer comment: `<!-- Generated by @content-generator on YYYY-MM-DD -->`

2. **Given** a request for "ROS 2 Services", **When** @content-generator runs, **Then** it:
   - Cites official ROS 2 documentation (ros.org/humble)
   - Includes working code (verified against ROS 2 Humble API)
   - Uses Economy Jetson Kit as default hardware context
   - Adds interactive components (collapsible sections, tabs for Python/C++)

3. **Given** a chapter about Isaac Sim, **When** @content-generator runs, **Then** it:
   - References NVIDIA Isaac Sim 4.0+ official docs
   - Includes "Train in cloud, deploy to Jetson" workflow
   - Shows explicit ONNX/TensorRT export steps
   - Warns about latency traps (Principle XI)

---

### User Story 2 - Research & Reference Finding with @reference-finder (Priority: P1)

**As a** course author,
**I want to** invoke `@reference-finder` to locate the latest papers, NVIDIA docs, and GitHub repos for a topic (e.g., "VLA models for humanoid robots"),
**So that** I get authoritative, up-to-date citations without manual research.

**Why this priority**: Technical accuracy (Constitution Principle III) depends on authoritative sources—this agent ensures all claims are verifiable.

**Independent Test**:
- Run: `@reference-finder "Find latest papers and docs on Vision-Language-Action models for robotics"`
- Verify: Returns 5-10 sources with URLs, publication dates, and relevance scores

**Acceptance Scenarios**:

1. **Given** a topic query, **When** @reference-finder is invoked, **Then** it returns:
   - 5-10 authoritative sources (arXiv, IEEE, NVIDIA docs, GitHub)
   - Full citation (title, authors, date, URL)
   - Relevance score (High/Medium/Low)
   - Brief summary (50-100 words per source)

2. **Given** query "Jetson Orin Nano specs", **When** @reference-finder runs, **Then** it:
   - Returns official NVIDIA Jetson specs page (developer.nvidia.com)
   - Verifies current price ($249 as of Dec 2025)
   - Includes TOPS performance (10 INT8)
   - Flags any pricing discrepancies

3. **Given** query "RT-2 robotics transformer", **When** @reference-finder runs, **Then** it:
   - Returns Google DeepMind's original paper (arXiv link)
   - Includes GitHub repo if available (google-deepmind/rt-2)
   - Lists related models (RT-1, Octo, OpenVLA)
   - Notes license restrictions (e.g., research-only)

---

### User Story 3 - Proofreading & Clarity with @proofreader (Priority: P2)

**As a** course author,
**I want to** invoke `@proofreader` on a draft chapter to fix grammar, simplify jargon, and ensure beginner-friendliness,
**So that** the final content is clear, error-free, and accessible to students with no robotics background.

**Why this priority**: Quality assurance—critical for credibility but not blocking initial content creation.

**Independent Test**:
- Run: `@proofreader "Check Module 1 Chapter 3 draft for clarity and grammar"`
- Verify: Returns line-by-line suggestions with explanations

**Acceptance Scenarios**:

1. **Given** a draft chapter, **When** @proofreader is invoked, **Then** it:
   - Flags grammatical errors (subject-verb agreement, tense inconsistencies)
   - Identifies overly complex sentences (>25 words)
   - Suggests simpler alternatives for jargon (e.g., "middleware" → "software layer that connects components")
   - Verifies all acronyms are defined on first use (e.g., "ROS 2 (Robot Operating System 2)")

2. **Given** a paragraph with passive voice, **When** @proofreader runs, **Then** it:
   - Highlights passive constructions ("The robot was controlled by the node")
   - Suggests active alternatives ("The node controlled the robot")
   - Explains readability improvement

3. **Given** content with undefined jargon, **When** @proofreader runs, **Then** it:
   - Flags undefined terms (e.g., "URDF" without expansion)
   - Suggests adding glossary links or inline definitions
   - Ensures beginner-friendliness (Constitution Principle III)

---

### User Story 4 - Quiz & Exercise Generation with @quiz-generator (Priority: P2)

**As a** course author,
**I want to** invoke `@quiz-generator` for a chapter to create 5 MCQs and 2 hands-on exercises,
**So that** students can test their understanding immediately after reading.

**Why this priority**: Enhances learning but not blocking initial content deployment.

**Independent Test**:
- Run: `@quiz-generator "Create quiz for Module 1 Chapter 3: ROS 2 Pub/Sub"`
- Verify: Returns 5 MCQs (with answers) and 2 coding exercises

**Acceptance Scenarios**:

1. **Given** a chapter, **When** @quiz-generator is invoked, **Then** it produces:
   - 5 multiple-choice questions (4 options each, 1 correct)
   - Questions test conceptual understanding (not rote memorization)
   - Answers are provided separately (hidden in collapsible section)
   - Questions cite specific chapter sections

2. **Given** a chapter on ROS 2 Pub/Sub, **When** @quiz-generator runs, **Then** exercises include:
   - "Modify the talker node to publish sensor data instead of strings"
   - "Implement a listener that filters messages by topic name"
   - Exercises are achievable with chapter content alone (no external research)

3. **Given** a chapter on Isaac Sim, **When** @quiz-generator runs, **Then** it:
   - Includes at least 1 simulation exercise
   - Provides starter code templates
   - Defines clear success criteria (e.g., "Robot should navigate to target in <30 seconds")

---

### User Story 5 - Summary Generation with @summary-writer (Priority: P3)

**As a** course author,
**I want to** invoke `@summary-writer` to create a 3-bullet TL;DR for any chapter,
**So that** readers can quickly grasp key takeaways before diving in.

**Why this priority**: Nice-to-have enhancement for navigation—not blocking core content.

**Independent Test**:
- Run: `@summary-writer "Summarize Module 2 Chapter 5: Isaac Sim Scene Authoring"`
- Verify: Returns exactly 3 bullets, each <20 words

**Acceptance Scenarios**:

1. **Given** a chapter, **When** @summary-writer is invoked, **Then** it produces:
   - Exactly 3 bullet points
   - Each bullet ≤20 words
   - Bullets capture: (1) main concept, (2) key technique, (3) practical outcome
   - Summary is placed at top of chapter (after title, before content)

2. **Given** a 2000-word chapter on VLA models, **When** @summary-writer runs, **Then** bullets might be:
   - "Vision-Language-Action models combine visual input, language commands, and robot actions"
   - "Examples: RT-1 (130k demos), RT-2 (multimodal transformer), Octo (open-source)"
   - "Deploy trained VLA to Jetson for <50ms inference in sim-to-real workflows"

3. **Given** a hardware chapter, **When** @summary-writer runs, **Then** it:
   - Includes pricing (e.g., "Economy Kit: $700 total")
   - Highlights key specs (e.g., "Jetson: 10 TOPS, 8GB RAM")
   - Mentions deployment context (e.g., "Edge inference <10ms latency")

---

### User Story 6 - Hardware Economics with @hardware-economist (Priority: P1)

**As a** course author,
**I want to** invoke `@hardware-economist` to verify all hardware prices and generate cost comparison tables,
**So that** the textbook maintains 100% pricing accuracy (Constitution Principle V).

**Why this priority**: Critical for trust—inaccurate pricing violates constitution and misleads students.

**Independent Test**:
- Run: `@hardware-economist "Verify Economy Jetson Kit pricing and generate comparison table"`
- Verify: Returns current prices with vendor links and alternative options

**Acceptance Scenarios**:

1. **Given** a hardware mention, **When** @hardware-economist is invoked, **Then** it:
   - Verifies current price against vendor website (NVIDIA, Intel, Amazon)
   - Flags discrepancies (e.g., "Spec says $249, but NVIDIA shows $269")
   - Generates markdown table with: Component, Price, Vendor Link, Last Verified

2. **Given** request for "Economy Jetson Kit pricing", **When** @hardware-economist runs, **Then** it produces:
   ```markdown
   | Component | Price | Vendor | Last Verified |
   |-----------|-------|--------|---------------|
   | Jetson Orin Nano Dev Kit | $249 | [NVIDIA](https://store.nvidia.com) | 2025-12-06 |
   | RealSense D435i | $349 | [Intel](https://www.intelrealsense.com) | 2025-12-06 |
   | Power + cables + SD | $100 | [Amazon](https://amazon.com) | 2025-12-06 |
   | **Total** | **$700** | - | - |
   ```

3. **Given** request for "Cloud vs. Edge cost comparison", **When** @hardware-economist runs, **Then** it:
   - Calculates AWS g5.xlarge quarterly cost ($1.006/hr × 5 hrs/week × 10 weeks ≈ $205)
   - Compares to one-time Jetson purchase ($700)
   - Highlights break-even point (e.g., "Cloud cheaper for 1 quarter, Jetson cheaper for ≥2 quarters")

---

### User Story 7 - Sim-to-Real Enforcement with @sim2real-priest (Priority: P1)

**As a** course author,
**I want to** invoke `@sim2real-priest` to review any chapter or code example for violations of Constitution Principle IV (Sim-to-Real First),
**So that** no content accidentally promotes dangerous cloud-robot control patterns.

**Why this priority**: Safety-critical—violating sim-to-real workflow can cause physical harm.

**Independent Test**:
- Run: `@sim2real-priest "Review this code for cloud-robot control patterns: [code snippet]"`
- Verify: Flags any network calls in control loops, suggests edge deployment

**Acceptance Scenarios**:

1. **Given** a code example, **When** @sim2real-priest is invoked, **Then** it:
   - Scans for network API calls (HTTP, WebSocket, gRPC) in control loops
   - Flags any "train and deploy in cloud" patterns
   - Ensures explicit separation: "Train in cloud, export, deploy to Jetson"
   - Adds latency warnings if network calls are present

2. **Given** code with `requests.post(api_endpoint, robot_cmd)`, **When** @sim2real-priest runs, **Then** it:
   - **REJECTS** with: "⚠️ LATENCY TRAP: Sending robot commands over network introduces 50-200ms latency. For real robots, deploy model to Jetson."
   - Suggests refactor: "Train model in cloud → Export to ONNX → Deploy to Jetson → Run inference locally"

3. **Given** a tutorial with "AWS Lambda controls robot", **When** @sim2real-priest runs, **Then** it:
   - **REJECTS** unless labeled "SIMULATION ONLY"
   - Requires adding Constitution Principle XI warning text
   - Suggests architecture: "Lambda for high-level planning, Jetson for real-time control"

4. **Given** valid sim-to-real example, **When** @sim2real-priest runs, **Then** it:
   - **APPROVES** if workflow is: "Train in cloud → Export → Deploy to Jetson → Run locally"
   - Verifies presence of export step (ONNX, TensorRT)
   - Confirms Jetson mentioned as deployment target

---

### User Story 8 - Urdu Translation with @urdu-translator (Priority: P3)

**As a** course author,
**I want to** invoke `@urdu-translator` to generate perfect technical Urdu translations for chapters,
**So that** Urdu-speaking students can access content in their native language (Constitution Principle VI).

**Why this priority**: Accessibility enhancement—important but not blocking initial launch.

**Independent Test**:
- Run: `@urdu-translator "Translate Module 1 Chapter 1 title and first paragraph to Urdu"`
- Verify: Returns grammatically correct Urdu with technical terms preserved

**Acceptance Scenarios**:

1. **Given** English chapter content, **When** @urdu-translator is invoked, **Then** it:
   - Translates prose to fluent Urdu
   - Preserves technical terms in English where no Urdu equivalent exists (e.g., "ROS 2" stays "ROS 2")
   - Provides Urdu translations for common terms (e.g., "Robot" → "روبوٹ", "sensor" → "سینسر")
   - Maintains markdown structure (headings, code blocks, lists)

2. **Given** "Robot Operating System 2", **When** @urdu-translator runs, **Then** it suggests:
   - "روبوٹک آپریٹنگ سسٹم 2" (transliteration)
   - Or "ROS 2 (روبوٹک آپریٹنگ سسٹم 2)" (hybrid)
   - Explains: "Keep 'ROS 2' for clarity, add Urdu in parentheses"

3. **Given** code comments in English, **When** @urdu-translator runs, **Then** it:
   - Translates comments to Urdu
   - Keeps code keywords in English (e.g., `def`, `class`, `import`)
   - Example: `# Initialize ROS 2 node` → `# ROS 2 نوڈ شروع کریں`

---

## Edge Cases

### Content Generation Edge Cases
- **Empty chapter request**: @content-generator should ask for clarification ("Please specify chapter topic and learning objectives")
- **Conflicting constitution principles**: Agent prioritizes safety (Principle XI) over all others
- **Outdated API references**: @reference-finder flags deprecated APIs (e.g., ROS 2 Foxy vs. Humble)
- **Overly long output**: @content-generator caps chapters at 3000 words, suggests splitting into sub-chapters

### Research Edge Cases
- **No sources found**: @reference-finder returns "No authoritative sources found. Suggest manual review or topic refinement."
- **Paywall sources**: Agent flags paywalled papers and suggests open-access alternatives
- **Contradictory sources**: Agent presents both views with "Note: Sources disagree on [X]. Recommend citing both."

### Proofreading Edge Cases
- **Non-English content**: @proofreader detects language and suggests: "This appears to be [Language]. Run @urdu-translator first if translation is needed."
- **Code blocks with errors**: Agent flags syntax errors separately from prose issues
- **Intentional jargon**: Author can override suggestions with comment: `<!-- @proofreader: jargon approved -->`

### Hardware Economics Edge Cases
- **Regional pricing differences**: @hardware-economist notes: "Prices verified for US market. International buyers should check local vendors."
- **Out-of-stock items**: Agent flags: "⚠️ RealSense D435i currently unavailable on Intel Store. Alternative: D455 ($329)."
- **Currency fluctuations**: Agent timestamps prices and suggests quarterly reviews

### Sim-to-Real Edge Cases
- **Legitimate cloud use cases**: @sim2real-priest allows cloud for:
  - High-level planning (not real-time control)
  - Data collection (not actuation)
  - Simulation environments (clearly labeled)
- **Hybrid architectures**: Agent approves: "Cloud model serving + Jetson client with <10ms local fallback"

### Translation Edge Cases
- **Technical terms without Urdu equivalents**: @urdu-translator keeps English terms and adds explanation
- **Right-to-left rendering**: Agent ensures MDX supports RTL CSS for Urdu chapters
- **Mixed language code**: Comments in Urdu, code in English (standard practice)

---

## Requirements *(mandatory)*

### Functional Requirements

#### FR-001: Agent Directory Structure
System MUST create the following directory structure:
```
/agents/
  ├── content-generator.md          # Bio + metadata
  ├── reference-finder.md
  ├── proofreader.md
  ├── quiz-generator.md
  ├── summary-writer.md
  ├── hardware-economist.md
  ├── sim2real-priest.md
  ├── urdu-translator.md
  └── skills/
      ├── content-generator.md      # 500+ word system prompt
      ├── reference-finder.md
      ├── proofreader.md
      ├── quiz-generator.md
      ├── summary-writer.md
      ├── hardware-economist.md
      ├── sim2real-priest.md
      └── urdu-translator.md
```

#### FR-002: Agent Bio Files
Each `/agents/<name>.md` file MUST contain:
- Agent name and role (1-sentence description)
- Expertise domain (2-3 bullet points)
- Input format (what the agent expects)
- Output format (what the agent produces)
- Example invocation
- Constitution principles the agent enforces

#### FR-003: Agent Skill Files
Each `/agents/skills/<name>.md` file MUST contain:
- System prompt (500+ words)
- Explicit instructions on constitution compliance
- Input/output schemas
- Example interactions (at least 2)
- Error handling guidelines
- Integration points with other agents

#### FR-004: Generated Content Tagging
All content generated by agents MUST include footer comment:
```html
<!-- Generated by @agent-name on YYYY-MM-DD -->
```

#### FR-005: Constitution Compliance
All agents MUST:
- Refuse to generate content violating constitution principles
- Cite specific principle when rejecting requests (e.g., "Rejected per Principle IV: Sim-to-Real First")
- Suggest constitution-compliant alternatives

#### FR-006: Agent Invocation
Agents MUST be invocable via:
- Command-line: `claude-code @agent-name "task description"`
- Git commit messages: `feat: Add VLA chapter (@content-generator)`
- Markdown comments: `<!-- @agent-name: review this section -->`

#### FR-007: Cross-Agent Orchestration
Agents MUST support chaining:
- Example: `@content-generator → @proofreader → @sim2real-priest`
- Each agent receives previous agent's output as input
- Final output includes all agent signatures

#### FR-008: Agent Output Validation
System MUST validate agent outputs:
- @content-generator: Valid MDX syntax, no broken links
- @reference-finder: All URLs return HTTP 200
- @hardware-economist: Prices verified within 30 days
- @sim2real-priest: No network calls in control loops

---

### Key Entities

- **Agent**: A specialized AI assistant with a defined role, expertise, and system prompt
  - Attributes: name, role, expertise_domain, input_format, output_format, constitution_principles
  - Relationships: Agents can be chained (output of one → input of next)

- **AgentSkill**: The system prompt and operational instructions for an agent
  - Attributes: system_prompt (500+ words), examples, error_handling, integration_points
  - Relationships: 1:1 with Agent

- **GeneratedContent**: Any chapter, section, or artifact produced by an agent
  - Attributes: content_body, agent_name, generation_date, constitution_check_results
  - Relationships: Many-to-one with Agent

- **ConstitutionPrinciple**: A rule from `/constitution.md` that agents must enforce
  - Attributes: principle_id (I-XI), title, enforcement_rules
  - Relationships: Many-to-many with Agents (agents enforce multiple principles)

---

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: All 8 agents successfully generate valid output for their domain (tested with 10 sample tasks each)
- **SC-002**: @content-generator produces MDX chapters passing Docusaurus build (0 errors)
- **SC-003**: @reference-finder returns 5+ authoritative sources for 100% of test queries
- **SC-004**: @proofreader catches 95%+ of grammar errors in test corpus (verified against Grammarly)
- **SC-005**: @quiz-generator creates quizzes with 100% factual accuracy (verified against chapter content)
- **SC-006**: @hardware-economist verifies prices within 24 hours (no stale data >30 days)
- **SC-007**: @sim2real-priest rejects 100% of cloud-robot control patterns in test suite
- **SC-008**: @urdu-translator produces grammatically correct Urdu (verified by native speaker)
- **SC-009**: All generated content includes agent signature footer comment (100% compliance)
- **SC-010**: Agent chaining (e.g., generator → proofreader → sim2real-priest) completes in <2 minutes

---

## Technical Architecture *(optional but recommended)*

### Agent Implementation Strategy

**Option 1: Claude Code Slash Commands** (Recommended)
- Each agent is a slash command in `.claude/commands/`
- Example: `.claude/commands/content-generator.md` contains system prompt
- Invocation: `/content-generator "Write chapter on ROS 2 Services"`

**Option 2: MCP (Model Context Protocol) Servers**
- Each agent runs as an MCP server
- Provides structured tools (e.g., `generate_chapter`, `find_references`)
- Allows programmatic chaining and output validation

**Option 3: GitHub Actions Workflows**
- Agents triggered via PR comments (e.g., `@content-generator review`)
- Output committed directly to PR
- Automatic constitution compliance checks

**Recommendation**: Start with Option 1 (slash commands) for simplicity, migrate to Option 2 (MCP) for advanced orchestration.

---

### Agent System Prompt Template

Each agent skill file follows this structure:

```markdown
# Agent: <Name>

## Role
<1-sentence description>

## Expertise Domain
- <Domain area 1>
- <Domain area 2>
- <Domain area 3>

## Constitution Principles Enforced
- Principle <N>: <Title> - <Enforcement rule>

## System Prompt (500+ words)

You are @<agent-name>, a specialized AI assistant for the Physical AI & Humanoid Robotics textbook project.

### Your Mission
<Detailed mission statement explaining the agent's purpose>

### Your Capabilities
<List of what the agent can do>

### Your Constraints
<List of what the agent MUST NOT do>

### Input Format
<Expected input structure>

### Output Format
<Required output structure>

### Constitution Compliance
<How this agent enforces specific principles>

### Quality Checks
<Self-validation steps before returning output>

## Example Interactions

### Example 1: <Scenario>
**Input**: <User request>
**Processing**: <Agent's reasoning>
**Output**: <Agent's response>

### Example 2: <Scenario>
**Input**: <User request>
**Processing**: <Agent's reasoning>
**Output**: <Agent's response>

## Error Handling
<How agent handles edge cases and failures>

## Integration Points
<How agent interacts with other agents>
```

---

## Non-Functional Requirements

### Performance
- **NFR-001**: Agent invocation MUST complete within 60 seconds for standard tasks
- **NFR-002**: Agent chaining (3 agents) MUST complete within 3 minutes
- **NFR-003**: Agent output validation MUST run in <5 seconds

### Reliability
- **NFR-004**: Agents MUST handle network failures gracefully (retry 3x with exponential backoff)
- **NFR-005**: Agents MUST validate all external sources (URLs return HTTP 200)

### Security
- **NFR-006**: Agent system prompts MUST NOT expose API keys or secrets
- **NFR-007**: Agents MUST sanitize user input (no code injection)

### Maintainability
- **NFR-008**: Agent system prompts MUST be version-controlled in `/agents/skills/`
- **NFR-009**: Agent updates MUST trigger regression tests (validate against test corpus)

---

## Implementation Plan *(high-level)*

### Phase 1: Foundation (Priority: P1)
1. Create `/agents/` and `/agents/skills/` directories
2. Implement @content-generator (most critical agent)
3. Implement @reference-finder (required for accuracy)
4. Implement @hardware-economist (required for pricing accuracy)
5. Implement @sim2real-priest (required for safety)

### Phase 2: Quality Assurance (Priority: P2)
6. Implement @proofreader (enhances quality)
7. Implement @quiz-generator (enhances learning)

### Phase 3: Enhancements (Priority: P3)
8. Implement @summary-writer (nice-to-have)
9. Implement @urdu-translator (accessibility)

### Phase 4: Orchestration
10. Build agent chaining system
11. Create test corpus for validation
12. Integrate with CI/CD for automated checks

---

## Risks & Mitigations

### Risk 1: Agent Hallucination
**Likelihood**: Medium
**Impact**: High (inaccurate content violates constitution)
**Mitigation**:
- @reference-finder verifies all sources
- @sim2real-priest enforces safety rules
- Human review required before merging agent-generated content

### Risk 2: Outdated Information
**Likelihood**: High (hardware prices and APIs change)
**Impact**: Medium (violates Principle III and V)
**Mitigation**:
- @hardware-economist runs quarterly price checks
- @reference-finder flags deprecated APIs
- CI/CD fails on stale data (>30 days for prices)

### Risk 3: Agent Conflicts
**Likelihood**: Low
**Impact**: Medium (agents give contradictory advice)
**Mitigation**:
- Establish priority order: Safety (sim2real-priest) > Accuracy (reference-finder) > Style (proofreader)
- Document conflict resolution rules in each agent's skill file

### Risk 4: Performance Degradation
**Likelihood**: Medium (agent chaining is slow)
**Impact**: Low (annoyance, not blocking)
**Mitigation**:
- Run agents in parallel where possible (e.g., proofreader + sim2real-priest)
- Cache expensive operations (reference lookups, price checks)
- Set 60-second timeout per agent

---

## Dependencies

- **Internal**: Constitution file (`.specify/memory/constitution.md`)
- **External**:
  - OpenAI API (for agent LLM backend)
  - Claude Code CLI (for slash command integration)
  - GitHub Actions (optional, for automated agent invocation)

---

## Open Questions

1. **Agent LLM Backend**: Use OpenAI GPT-4 or Claude Opus for agent inference?
   - **Recommendation**: Claude Opus (better at following complex instructions)

2. **Agent Output Storage**: Should agents commit directly to repo or create PRs?
   - **Recommendation**: Create PRs for review (safety-critical content)

3. **Agent Billing**: Who pays for agent API calls during development?
   - **Recommendation**: Use project API key with usage monitoring

4. **Agent Versioning**: How do we version agent system prompts?
   - **Recommendation**: Git tags (e.g., `v1.0-content-generator`)

---

## Acceptance Checklist

Before marking this feature as complete, verify:

- [ ] All 8 `/agents/<name>.md` bio files exist
- [ ] All 8 `/agents/skills/<name>.md` skill files exist (500+ words each)
- [ ] Each agent successfully processes 10 test tasks
- [ ] All generated content includes agent signature footer
- [ ] @sim2real-priest rejects 100% of cloud-robot control patterns
- [ ] @hardware-economist verifies all prices within 24 hours
- [ ] Agent chaining (3 agents) completes within 3 minutes
- [ ] Human SME review approves all agent-generated test content
- [ ] Documentation added to README explaining agent usage

---

## Constitution Alignment Checklist

This feature directly supports the following constitution principles:

- [x] **Principle II: Specification-First Development** - Agents enforce spec compliance
- [x] **Principle III: Accuracy & Technical Truth** - @reference-finder ensures citations
- [x] **Principle IV: Sim-to-Real First Philosophy** - @sim2real-priest enforces workflow
- [x] **Principle V: Cost Transparency** - @hardware-economist verifies pricing
- [x] **Principle VI: Urdu + Personalization Ready** - @urdu-translator enables accessibility
- [x] **Principle IX: Reusable Intelligence via Claude Code Subagents** - Core feature
- [x] **Principle XI: Latency Trap Rule** - @sim2real-priest enforces warnings

---

## Related Documents

- Constitution: `.specify/memory/constitution.md`
- Agent Bio Template: `agents/README.md` (to be created)
- Agent Skill Template: `agents/skills/README.md` (to be created)
- Test Corpus: `tests/agent-validation/` (to be created)

---

**Specification Version**: 1.0
**Last Updated**: 2025-12-06
**Author**: Claude Code (Opus 4.5)
**Status**: Ready for Review
