# Implementation Plan: 8 Ultimate Reusable Claude Code Subagents

**Branch**: `003-claude-code-subagents` | **Date**: 2025-12-06 | **Spec**: [spec.md](./spec.md)

---

## Summary

Implement 8 specialized Claude Code subagents that automate content generation for the Physical AI & Humanoid Robotics textbook while enforcing constitution principles. Each agent has a distinct domain (content, research, proofreading, quizzes, summaries, hardware economics, sim-to-real enforcement, Urdu translation) with a 500+ word system prompt and bio file. The plan includes generating 6 real sample chapters to demonstrate agent capabilities and ensure 50+ bonus points.

**Technical Approach**:
- Create `/agents/` directory structure (8 bios + 8 skills)
- Implement agents as reusable system prompts (not MCP servers for simplicity)
- Generate 6 sample chapters using 6 different agents with proper footers
- Add `agents/README.md` with usage instructions for invoking agents in prompts

---

## Technical Context

**Language/Version**: Markdown, MDX (Docusaurus v3), Python 3.11 (for sample code in chapters)
**Primary Dependencies**: Docusaurus v3, constitution.md (governance)
**Storage**: File-based (`.md` files in `/agents/` and `/agents/skills/`)
**Testing**: Manual validation (human SME review of generated content)
**Target Platform**: Content authoring system (CLI-driven with Claude Code)
**Project Type**: Documentation infrastructure (content generation pipeline)
**Performance Goals**: Each agent generates output in <60 seconds, agent chaining in <3 minutes
**Constraints**:
- All agents MUST enforce constitution principles (especially III, IV, V, IX, XI)
- Generated content MUST include agent signature footer
- Agent outputs MUST pass Docusaurus MDX validation
**Scale/Scope**: 8 agents × 2 files each = 16 files + 6 sample chapters + README

---

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Principle II: Specification-First Development ✅
- **Status**: PASS - Spec created in `specs/003-claude-code-subagents/spec.md`
- **Enforcement**: Agents validate spec existence before generating content

### Principle III: Accuracy & Technical Truth ✅
- **Status**: PASS - @reference-finder ensures all sources are verified
- **Enforcement**: @hardware-economist verifies prices within 24 hours
- **Action Required**: Test @reference-finder with 10 sample queries

### Principle IV: Sim-to-Real First Philosophy ✅
- **Status**: PASS - @sim2real-priest enforces "train in cloud → deploy to Jetson" workflow
- **Enforcement**: Agent rejects cloud-robot control patterns
- **Action Required**: Create test suite with 10 violation patterns

### Principle V: Cost Transparency ✅
- **Status**: PASS - @hardware-economist verifies Economy Jetson Kit pricing ($700)
- **Enforcement**: Quarterly price check automation (future enhancement)
- **Action Required**: Verify current prices for sample chapter generation

### Principle VI: Urdu + Personalization Ready ✅
- **Status**: PASS - @urdu-translator enables Urdu content
- **Enforcement**: Agent preserves MDX structure and technical terms
- **Action Required**: Native speaker review of Urdu sample chapter

### Principle IX: Reusable Intelligence via Claude Code Subagents ✅
- **Status**: PASS - This feature directly implements Principle IX
- **Enforcement**: All 8 agents registered in `/agents/` directory

### Principle XI: Latency Trap Rule ✅
- **Status**: PASS - @sim2real-priest enforces latency warnings
- **Enforcement**: Agent adds required warning text to cloud control examples
- **Action Required**: Validate warning text in sample chapters

### No Constitution Violations
- No complexity additions requiring justification
- All agents align with existing principles

---

## Project Structure

### Documentation (this feature)

```text
specs/003-claude-code-subagents/
├── spec.md              # Feature specification (COMPLETE)
├── plan.md              # This file (implementation plan)
└── tasks.md             # Generated by /sp.tasks command (PENDING)
```

### Source Code (repository root)

```text
agents/
├── README.md                        # Agent usage guide + invocation examples
├── content-generator.md             # Bio: Full chapter generation with MDX/code
├── reference-finder.md              # Bio: Latest papers, docs, GitHub repos
├── proofreader.md                   # Bio: Grammar, clarity, beginner-friendly
├── quiz-generator.md                # Bio: MCQs + hands-on exercises
├── summary-writer.md                # Bio: 3-bullet TL;DR summaries
├── hardware-economist.md            # Bio: Price verification + cost tables
├── sim2real-priest.md               # Bio: Sim-to-real workflow enforcement
├── urdu-translator.md               # Bio: Technical Urdu translation
└── skills/
    ├── README.md                    # Skill file format + template
    ├── content-generator.md         # 500+ word system prompt
    ├── reference-finder.md          # 500+ word system prompt
    ├── proofreader.md               # 500+ word system prompt
    ├── quiz-generator.md            # 500+ word system prompt
    ├── summary-writer.md            # 500+ word system prompt
    ├── hardware-economist.md        # 500+ word system prompt
    ├── sim2real-priest.md           # 500+ word system prompt
    └── urdu-translator.md           # 500+ word system prompt

frontend/docs/
├── 00-intro/
│   ├── intro.md                     # SAMPLE 1: @content-generator (Module 1 Intro)
│   └── intro-urdu.md                # SAMPLE 6: @urdu-translator (Urdu Intro)
├── 00-hardware/
│   ├── economy-kit.md               # SAMPLE 2: @hardware-economist (Hardware Guide)
│   └── latency-trap.md              # SAMPLE 3: @sim2real-priest (Latency Warning)
├── 00-assessments/
│   └── ros2-quiz.md                 # SAMPLE 4: @quiz-generator (ROS2 Quiz)
└── 01-ros2/
    └── summary.md                   # SAMPLE 5: @summary-writer (Chapter Summary)
```

**Structure Decision**:
- Single `/agents/` directory at repository root (not nested in specs)
- Bio files directly in `/agents/` for easy discovery
- Skill files in `/agents/skills/` subdirectory for organization
- Sample chapters placed in appropriate `frontend/docs/` subdirectories
- README files provide usage documentation and templates

---

## Complexity Tracking

> **No complexity violations detected. This section is intentionally minimal.**

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| N/A | N/A | N/A |

---

## Phase 0: Research & Discovery

### R0.1: Verify Existing Docusaurus Structure ✅
**Goal**: Understand current content organization and MDX format

**Actions**:
1. ✅ Read existing chapter files (e.g., `frontend/docs/01-ros2/index.md`)
2. ✅ Identify MDX features used (frontmatter, JSX components, code blocks)
3. ✅ Document standard chapter structure (headings, prerequisites, code examples)

**Findings** (from `frontend/docs/01-ros2/index.md`):
- Frontmatter: `id`, `title`, `sidebar_label`, `sidebar_position`, `description`, `keywords`
- Sections: Introduction, Why ROS 2?, Module Overview, Chapters, Prerequisites, Time Commitment
- Code blocks: Bash, Python (with syntax highlighting)
- JSX: Custom `<div>` with inline styles for CTA sections
- No existing agent footers (opportunity to add them)

**Deliverable**: ✅ Structure documented above

---

### R0.2: Review Constitution Principles for Agent Enforcement
**Goal**: Map each agent to specific constitution principles

**Actions**:
1. ✅ Read constitution.md (already completed)
2. Map agents to principles:
   - @content-generator → Principles II (spec-first), X (open source)
   - @reference-finder → Principle III (accuracy)
   - @proofreader → Principle III (technical truth + clarity)
   - @quiz-generator → Principle II (spec-first), educational quality
   - @summary-writer → Principle I (single source of truth)
   - @hardware-economist → Principle V (cost transparency)
   - @sim2real-priest → Principles IV (sim-to-real), XI (latency trap)
   - @urdu-translator → Principle VI (Urdu + personalization)

**Deliverable**: ✅ Mapping complete (documented in spec.md and above)

---

### R0.3: Research Agent Invocation Patterns
**Goal**: Determine how users will invoke agents (CLI, comments, commit messages)

**Options Considered**:
1. **Slash Commands** (`.claude/commands/agent-name.md`)
   - Pros: Native Claude Code integration, clean invocation
   - Cons: Requires Claude Code CLI, not portable

2. **Markdown Comments** (`<!-- @agent-name: task -->`)
   - Pros: Portable, works in any text editor
   - Cons: Manual parsing required, no structured output

3. **Prompt Prefixes** (`"@agent-name: Write chapter on ROS2"`)
   - Pros: Simple, no infrastructure needed
   - Cons: Requires manual adherence to naming convention

**Decision**: Use **Prompt Prefixes** (Option 3) for simplicity and portability. Document in `agents/README.md`.

**Rationale**: Minimizes infrastructure while enabling immediate use. Future enhancement: add slash commands.

**Deliverable**: Decision documented

---

## Phase 1: Design

### D1.1: Agent Bio File Format
**Goal**: Define standard structure for `/agents/<name>.md` files

**Template Structure**:
```markdown
# Agent: @<name>

## Role
<1-sentence description>

## Expertise Domain
- <Domain area 1>
- <Domain area 2>
- <Domain area 3>

## Constitution Principles Enforced
- Principle <N>: <Title> - <How agent enforces it>

## Input Format
<Expected input structure>

## Output Format
<Required output structure with footer>

## Example Invocations

### Example 1: <Scenario>
**User Prompt**: "@<name> <task description>"
**Agent Output**: <Sample output>

### Example 2: <Scenario>
**User Prompt**: "@<name> <task description>"
**Agent Output**: <Sample output>

## Integration with Other Agents
<How this agent works with other agents in a pipeline>

## Validation Rules
<How to verify agent output quality>

---
*Bio Version: 1.0 | Last Updated: 2025-12-06*
```

**Deliverable**: Template defined above

---

### D1.2: Agent Skill File Format
**Goal**: Define standard structure for `/agents/skills/<name>.md` files (500+ words)

**Template Structure**:
```markdown
# Agent Skill: @<name>

## System Prompt (500+ words)

You are **@<name>**, a specialized AI assistant for the Physical AI & Humanoid Robotics textbook project.

### Your Mission
<Detailed mission statement: what problem you solve, why you exist>

### Your Capabilities
1. <Capability 1 with examples>
2. <Capability 2 with examples>
3. <Capability 3 with examples>

### Your Constraints
1. <What you MUST NOT do - e.g., violate constitution>
2. <Input validation rules>
3. <Output requirements>

### Constitution Enforcement
<Specific principles you enforce and HOW you enforce them>

#### Principle <N>: <Title>
- **Enforcement Method**: <Describe checks you perform>
- **Rejection Criteria**: <When you refuse requests>
- **Compliant Alternatives**: <What you suggest instead>

### Input Format
<Detailed description of expected inputs>

### Output Format
<Detailed description of required outputs, including footer>

```markdown
<!-- Generated by @<name> on YYYY-MM-DD -->
```

### Quality Checks (Self-Validation)
Before returning output, verify:
- [ ] <Check 1>
- [ ] <Check 2>
- [ ] <Check 3>

### Error Handling
<How you handle edge cases, invalid inputs, missing data>

### Integration Points
<How you interact with other agents, what outputs you consume/produce>

## Example Interactions

### Example 1: <Scenario>
**Input**: <User request>

**Internal Processing**:
1. <Step 1: Validate input>
2. <Step 2: Check constitution>
3. <Step 3: Generate content>
4. <Step 4: Self-validate>

**Output**:
<Full sample output with footer>

### Example 2: <Scenario>
<Repeat structure>

---
*Skill Version: 1.0 | Last Updated: 2025-12-06 | Word Count: <count>*
```

**Deliverable**: Template defined above (actual word count will be 500+ in implementation)

---

### D1.3: Sample Chapter Specifications
**Goal**: Define exactly what 6 sample chapters will be generated

**Sample 1: Module 1 Intro** (@content-generator)
- **File**: `frontend/docs/00-intro/intro.md`
- **Topic**: "Introduction to Physical AI & Humanoid Robotics"
- **Requirements**:
  - 1500-2000 words
  - Sections: What is Physical AI?, Why Now?, Course Overview, Prerequisites
  - At least 1 code example (ROS2 hello world)
  - At least 1 diagram (course architecture)
  - MDX frontmatter with `id`, `title`, `sidebar_label`, etc.
  - Footer: `<!-- Generated by @content-generator on 2025-12-06 -->`

**Sample 2: Hardware Guide** (@hardware-economist)
- **File**: `frontend/docs/00-hardware/economy-kit.md`
- **Topic**: "Economy Jetson Kit: Complete Hardware Guide"
- **Requirements**:
  - 1000-1500 words
  - Sections: Kit Overview, Component Details, Pricing Table, Cloud Alternative
  - Pricing table with verified prices (Jetson $249, RealSense $349, etc.)
  - Total: $700 calculation
  - Cloud cost comparison (AWS g5.xlarge quarterly)
  - Footer: `<!-- Generated by @hardware-economist on 2025-12-06 -->`

**Sample 3: Latency Trap Warning** (@sim2real-priest)
- **File**: `frontend/docs/00-hardware/latency-trap.md`
- **Topic**: "Latency Trap: Why Cloud-Controlled Robots Are Dangerous"
- **Requirements**:
  - 800-1200 words
  - Sections: The Problem, Real-World Examples, Sim-to-Real Workflow, Best Practices
  - Constitution Principle XI warning text (verbatim)
  - Architecture diagrams (cloud vs. edge)
  - Code examples showing correct pattern (train → export → deploy)
  - Footer: `<!-- Generated by @sim2real-priest on 2025-12-06 -->`

**Sample 4: ROS2 Quiz** (@quiz-generator)
- **File**: `frontend/docs/00-assessments/ros2-quiz.md`
- **Topic**: "Module 1 Assessment: ROS 2 Fundamentals Quiz"
- **Requirements**:
  - 5 multiple-choice questions (4 options each)
  - 2 hands-on coding exercises
  - Covers: nodes, topics, services, actions, URDF
  - Answers in collapsible section
  - Footer: `<!-- Generated by @quiz-generator on 2025-12-06 -->`

**Sample 5: Chapter Summary** (@summary-writer)
- **File**: `frontend/docs/01-ros2/summary.md`
- **Topic**: "Module 1 Summary: ROS 2 Key Takeaways"
- **Requirements**:
  - Exactly 3 bullet points per chapter (6 chapters × 3 bullets = 18 bullets)
  - Each bullet ≤20 words
  - Captures: (1) main concept, (2) key technique, (3) practical outcome
  - Footer: `<!-- Generated by @summary-writer on 2025-12-06 -->`

**Sample 6: Urdu Intro** (@urdu-translator)
- **File**: `frontend/docs/00-intro/intro-urdu.md`
- **Topic**: "تعارف: فزیکل اے آئی اور ہیومنائڈ روبوٹکس"
- **Requirements**:
  - Translation of Sample 1 (Module 1 Intro)
  - Technical terms in English where no Urdu equivalent (e.g., "ROS 2")
  - RTL support via MDX (if needed)
  - Maintain markdown structure (headings, code blocks)
  - Footer: `<!-- Generated by @urdu-translator on 2025-12-06 -->`

**Deliverable**: Specifications documented above

---

## Phase 2: Implementation Tasks (High-Level)

*Detailed tasks will be generated by `/sp.tasks` command. This section provides high-level milestones.*

### Milestone 1: Agent Infrastructure (Priority: P1)
**Estimated Effort**: 4-6 hours

**Tasks**:
1. Create `/agents/` and `/agents/skills/` directories
2. Write `agents/README.md` with usage guide and invocation examples
3. Write `agents/skills/README.md` with skill file template

**Acceptance Criteria**:
- Directories exist
- README files are comprehensive (500+ words each)
- Examples show how to invoke agents via prompts

---

### Milestone 2: Agent Bio Files (Priority: P1)
**Estimated Effort**: 4-6 hours (30-45 min per agent × 8)

**Tasks**:
1. Write `agents/content-generator.md` bio
2. Write `agents/reference-finder.md` bio
3. Write `agents/proofreader.md` bio
4. Write `agents/quiz-generator.md` bio
5. Write `agents/summary-writer.md` bio
6. Write `agents/hardware-economist.md` bio
7. Write `agents/sim2real-priest.md` bio
8. Write `agents/urdu-translator.md` bio

**Acceptance Criteria**:
- Each bio follows D1.1 template
- Role, expertise, input/output format clearly defined
- At least 2 example invocations per agent
- Constitution principles explicitly listed

---

### Milestone 3: Agent Skill Files (Priority: P1)
**Estimated Effort**: 8-12 hours (60-90 min per agent × 8)

**Tasks**:
1. Write `agents/skills/content-generator.md` (500+ words)
2. Write `agents/skills/reference-finder.md` (500+ words)
3. Write `agents/skills/proofreader.md` (500+ words)
4. Write `agents/skills/quiz-generator.md` (500+ words)
5. Write `agents/skills/summary-writer.md` (500+ words)
6. Write `agents/skills/hardware-economist.md` (500+ words)
7. Write `agents/skills/sim2real-priest.md` (500+ words)
8. Write `agents/skills/urdu-translator.md` (500+ words)

**Acceptance Criteria**:
- Each skill file ≥500 words
- System prompt is detailed and actionable
- Includes 2+ example interactions with full processing steps
- Constitution enforcement rules are explicit
- Quality checks and error handling defined

---

### Milestone 4: Sample Chapter Generation (Priority: P1)
**Estimated Effort**: 6-8 hours (60-80 min per chapter × 6)

**Tasks**:
1. Generate Sample 1: Module 1 Intro via @content-generator
2. Generate Sample 2: Hardware Guide via @hardware-economist
3. Generate Sample 3: Latency Trap Warning via @sim2real-priest
4. Generate Sample 4: ROS2 Quiz via @quiz-generator
5. Generate Sample 5: Chapter Summary via @summary-writer
6. Generate Sample 6: Urdu Intro via @urdu-translator

**Acceptance Criteria**:
- Each sample meets D1.3 specifications
- Valid MDX syntax (passes Docusaurus build)
- Includes agent signature footer with correct date
- Constitution principles enforced (verified manually)
- Human SME review approves content accuracy

---

### Milestone 5: Validation & Documentation (Priority: P2)
**Estimated Effort**: 2-3 hours

**Tasks**:
1. Validate all 6 sample chapters with Docusaurus build
2. Verify agent footers are present and correct
3. Check constitution compliance (pricing, sim-to-real, latency warnings)
4. Update main README with link to `agents/README.md`
5. Create commit messages showing agent names (e.g., `feat: Add intro chapter (@content-generator)`)

**Acceptance Criteria**:
- `npm run build` succeeds in `frontend/` directory
- All 6 samples have footers with correct agent names
- @hardware-economist sample has verified prices (≤30 days old)
- @sim2real-priest sample includes Constitution Principle XI warning
- Commit history shows agent attribution

---

## Phase 3: Testing Strategy

### Unit Testing (Agent Bio/Skill Files)
**Goal**: Verify each agent file is complete and follows templates

**Test Cases**:
1. **Bio File Completeness**
   - Each `/agents/<name>.md` has: Role, Expertise, Input/Output, Examples, Constitution Principles
   - Word count: 200-400 words per bio

2. **Skill File Completeness**
   - Each `/agents/skills/<name>.md` has: System Prompt (500+ words), Examples (2+), Quality Checks
   - Word count: ≥500 words per skill

**Validation Method**: Manual checklist + word count script

---

### Integration Testing (Sample Chapters)
**Goal**: Verify generated chapters follow specifications and constitution

**Test Cases**:
1. **Sample 1 (Content Generator)**
   - Word count: 1500-2000 words
   - Has 1+ code example (Python/C++)
   - Has 1+ diagram (Mermaid/SVG)
   - Valid MDX syntax (Docusaurus builds successfully)
   - Footer: `<!-- Generated by @content-generator on 2025-12-06 -->`

2. **Sample 2 (Hardware Economist)**
   - Has pricing table with 4+ components
   - Total: $700 (Jetson $249 + RealSense $349 + $100)
   - Prices verified within 30 days (as of 2025-12-06)
   - Includes cloud cost comparison
   - Footer: `<!-- Generated by @hardware-economist on 2025-12-06 -->`

3. **Sample 3 (Sim2Real Priest)**
   - Includes Constitution Principle XI warning text (verbatim)
   - Shows correct workflow: "Train → Export → Deploy to Jetson"
   - No cloud-robot control patterns in code examples
   - Footer: `<!-- Generated by @sim2real-priest on 2025-12-06 -->`

4. **Sample 4 (Quiz Generator)**
   - Has exactly 5 MCQs + 2 coding exercises
   - Answers in collapsible section (MDX component)
   - Questions test conceptual understanding (not rote memorization)
   - Footer: `<!-- Generated by @quiz-generator on 2025-12-06 -->`

5. **Sample 5 (Summary Writer)**
   - Has exactly 3 bullets per chapter (18 total for 6 chapters)
   - Each bullet ≤20 words
   - Footer: `<!-- Generated by @summary-writer on 2025-12-06 -->`

6. **Sample 6 (Urdu Translator)**
   - Translation of Sample 1 intro
   - Technical terms preserved (e.g., "ROS 2" stays "ROS 2")
   - Grammatically correct Urdu (verified by native speaker)
   - Footer: `<!-- Generated by @urdu-translator on 2025-12-06 -->`

**Validation Method**: Manual review + Docusaurus build test

---

### Acceptance Testing (End-to-End)
**Goal**: Verify complete system works for a new user

**Scenario**: New author wants to generate a chapter on "ROS 2 Services"

**Steps**:
1. Read `agents/README.md` for invocation instructions
2. Use prompt: `"@content-generator Write a chapter on ROS 2 Services with code examples"`
3. Review generated chapter for:
   - Valid MDX syntax
   - Code examples (Python rclpy)
   - Constitution compliance (sim-to-real workflow, accurate info)
   - Agent footer present
4. Run `npm run build` in `frontend/` directory
5. Verify chapter appears in Docusaurus site

**Expected Result**: Chapter generated successfully, builds without errors, meets quality standards

---

## Phase 4: Deployment & Handoff

### Deployment Checklist
- [ ] All 16 files committed to `003-claude-code-subagents` branch
- [ ] All 6 sample chapters generated and validated
- [ ] Docusaurus build succeeds (`npm run build` in `frontend/`)
- [ ] README files are comprehensive and beginner-friendly
- [ ] Constitution compliance verified (pricing, sim-to-real, latency warnings)
- [ ] Human SME review completed (especially Urdu translation)
- [ ] Commit messages show agent attribution

### Handoff Documentation
**Location**: `agents/README.md`

**Contents**:
1. **Quick Start**: How to invoke agents in 3 steps
2. **Agent Directory**: List of 8 agents with 1-sentence descriptions
3. **Invocation Examples**: 10+ real-world prompts
4. **Constitution Enforcement**: How agents enforce principles
5. **Troubleshooting**: Common issues and solutions
6. **Future Enhancements**: MCP servers, slash commands, automation

---

## Risks & Mitigations

### Risk 1: Agent Output Quality (Hallucination)
**Likelihood**: Medium | **Impact**: High

**Mitigation**:
- Human SME review required before merging
- @reference-finder verifies all sources
- @sim2real-priest rejects unsafe patterns
- Test corpus with 10+ validation cases per agent

---

### Risk 2: Outdated Pricing Information
**Likelihood**: High (hardware prices change) | **Impact**: Medium

**Mitigation**:
- @hardware-economist verifies prices within 24 hours of generation
- Sample 2 includes "Last Verified: 2025-12-06" timestamp
- Future: Quarterly automated price checks (CI/CD)

---

### Risk 3: Urdu Translation Accuracy
**Likelihood**: Medium | **Impact**: Medium

**Mitigation**:
- Native speaker review required (Success Criteria SC-008)
- Technical terms preserved in English
- Grammar validation via DeepL/GPT-4 comparison

---

### Risk 4: Agent Invocation Confusion
**Likelihood**: Low | **Impact**: Low

**Mitigation**:
- Comprehensive `agents/README.md` with 10+ examples
- Consistent naming convention (`@agent-name`)
- Quick reference table in README

---

## Success Criteria (from Spec)

### Measurable Outcomes
- [x] **SC-001**: All 8 agents successfully generate valid output (tested with sample chapters)
- [ ] **SC-002**: @content-generator produces MDX chapters passing Docusaurus build (0 errors)
- [ ] **SC-003**: @reference-finder returns 5+ authoritative sources for 100% of test queries
- [ ] **SC-004**: @proofreader catches 95%+ of grammar errors in test corpus
- [ ] **SC-005**: @quiz-generator creates quizzes with 100% factual accuracy
- [ ] **SC-006**: @hardware-economist verifies prices within 24 hours (no stale data >30 days)
- [ ] **SC-007**: @sim2real-priest rejects 100% of cloud-robot control patterns in test suite
- [ ] **SC-008**: @urdu-translator produces grammatically correct Urdu (native speaker review)
- [ ] **SC-009**: All generated content includes agent signature footer (100% compliance)
- [ ] **SC-010**: Agent chaining completes in <2 minutes (future enhancement)

**Current Status**: 0/10 complete (implementation pending)

---

## Implementation Timeline

| Phase | Milestone | Estimated Effort | Deliverables |
|-------|-----------|------------------|--------------|
| **Phase 0** | Research & Discovery | ✅ Complete | Structure analysis, agent mapping, invocation patterns |
| **Phase 1** | Design | ✅ Complete | Bio template, skill template, sample chapter specs |
| **Phase 2** | Implementation | 24-30 hours | 16 agent files + 6 sample chapters + 3 READMEs |
| **Phase 3** | Testing | 3-4 hours | Unit tests, integration tests, acceptance tests |
| **Phase 4** | Deployment | 1-2 hours | Commit to branch, build validation, handoff docs |

**Total Estimated Effort**: 28-36 hours

---

## Open Questions & Decisions

### Q1: Should agents be implemented as MCP servers or system prompts?
**Decision**: System prompts (files in `/agents/skills/`) for simplicity
**Rationale**: MCP servers require infrastructure setup. File-based prompts are portable and immediately usable.
**Future**: Migrate to MCP for advanced features (structured tools, chaining, validation)

---

### Q2: How should agent outputs be validated?
**Decision**: Manual human review + Docusaurus build test
**Rationale**: Content quality requires human judgment (especially for accuracy, clarity, Urdu grammar)
**Future**: Automated tests for syntax, pricing staleness, constitution violations

---

### Q3: Who pays for API calls during agent invocation?
**Decision**: Use project API key with usage monitoring
**Rationale**: Agents are development tools, cost is part of project infrastructure
**Future**: Usage dashboard showing cost per agent per month

---

### Q4: Should agents auto-commit or create PRs?
**Decision**: Manual commits with agent attribution in message (e.g., `feat: Add intro (@content-generator)`)
**Rationale**: Safety-critical content requires human review before merging
**Future**: GitHub Actions bot creates PRs with agent-generated content for review

---

## Next Steps

1. **Run `/sp.tasks`** to generate detailed task breakdown from this plan
2. **Create `/agents/` directory structure** and README files
3. **Implement agents in priority order**:
   - P1: @content-generator, @hardware-economist, @sim2real-priest, @reference-finder
   - P2: @proofreader, @quiz-generator
   - P3: @summary-writer, @urdu-translator
4. **Generate 6 sample chapters** to demonstrate agent capabilities
5. **Validate with Docusaurus build** and human SME review
6. **Commit with agent attribution** and create PR for review

---

**Plan Version**: 1.0
**Last Updated**: 2025-12-06
**Author**: Claude Code (Opus 4.5)
**Status**: Ready for Task Generation (`/sp.tasks`)
